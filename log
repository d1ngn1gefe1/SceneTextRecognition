2016-07-05 11:59:35,078 loading training data
2016-07-05 11:59:35,217 loading test data
2016-07-05 11:59:36,140 epoch 0/20000, step 0/62500
2016-07-05 11:59:40,119 loss: 30.011892
2016-07-05 11:59:54,941 model saved in file: /home/local/ANT/zelunluo/Documents/checkpoint/model.ckpt
2016-07-05 11:59:54,941 epoch 0/20000, step 1/62500
2016-07-05 11:59:58,919 loss: 26.714569
2016-07-05 12:00:13,189 epoch 0/20000, step 2/62500
2016-07-05 12:00:17,163 loss: 26.873379
2016-07-05 12:00:31,454 epoch 0/20000, step 3/62500
2016-07-05 12:00:35,432 loss: 28.823456
2016-07-05 12:00:49,709 epoch 0/20000, step 4/62500
2016-07-05 12:00:53,693 loss: 27.939684
2016-07-05 12:01:08,009 epoch 0/20000, step 5/62500
2016-07-05 12:01:11,993 loss: 26.322403
2016-07-05 12:01:26,309 epoch 0/20000, step 6/62500
2016-07-05 12:01:30,292 loss: 27.311077
2016-07-05 12:01:44,584 epoch 0/20000, step 7/62500
2016-07-05 12:01:48,564 loss: 29.062143
2016-07-05 12:02:02,919 epoch 0/20000, step 8/62500
2016-07-05 12:02:06,896 loss: 27.290976
2016-07-05 12:02:21,162 epoch 0/20000, step 9/62500
2016-07-05 12:02:25,143 loss: 26.480299
2016-07-05 12:02:39,471 epoch 0/20000, step 10/62500
2016-07-05 12:02:43,447 loss: 30.125607
2016-07-05 12:02:57,669 epoch 0/20000, step 11/62500
2016-07-05 12:03:01,648 loss: 26.287781
2016-07-05 12:03:15,931 epoch 0/20000, step 12/62500
2016-07-05 12:03:19,905 loss: 27.124847
2016-07-05 12:03:34,578 epoch 0/20000, step 13/62500
2016-07-05 12:03:39,151 loss: 29.761095
2016-07-05 12:03:53,394 epoch 0/20000, step 14/62500
2016-07-05 12:03:57,370 loss: 26.132601
2016-07-05 12:04:11,635 epoch 0/20000, step 15/62500
2016-07-05 12:04:15,614 loss: 27.518299
2016-07-05 12:04:29,878 epoch 0/20000, step 16/62500
2016-07-05 12:04:33,859 loss: 27.880646
2016-07-05 12:04:48,735 epoch 0/20000, step 17/62500
2016-07-05 12:04:52,709 loss: 26.965405
2016-07-05 12:05:06,989 epoch 0/20000, step 18/62500
2016-07-05 12:05:10,973 loss: 28.648209
2016-07-05 12:05:25,470 epoch 0/20000, step 19/62500
2016-07-05 12:05:29,447 loss: 27.223263
2016-07-05 12:05:43,768 epoch 0/20000, step 20/62500
2016-07-05 12:05:47,754 loss: 26.784489
2016-07-05 12:06:02,164 epoch 0/20000, step 21/62500
2016-07-05 12:06:06,152 loss: 26.323936
2016-07-05 12:06:20,378 epoch 0/20000, step 22/62500
2016-07-05 12:06:24,352 loss: 28.984623
2016-07-05 12:06:38,658 epoch 0/20000, step 23/62500
2016-07-05 12:06:42,642 loss: 26.412809
2016-07-05 12:06:56,957 epoch 0/20000, step 24/62500
2016-07-05 12:07:00,942 loss: 26.323713
2016-07-05 12:07:15,225 epoch 0/20000, step 25/62500
2016-07-05 12:07:19,204 loss: 29.974850
2016-07-05 12:07:33,486 epoch 0/20000, step 26/62500
2016-07-05 12:07:37,470 loss: 26.685837
2016-07-05 12:07:51,890 epoch 0/20000, step 27/62500
2016-07-05 12:07:55,871 loss: 26.841423
2016-07-05 12:08:10,229 epoch 0/20000, step 28/62500
2016-07-05 12:08:14,202 loss: 28.787178
2016-07-05 12:08:28,515 epoch 0/20000, step 29/62500
2016-07-05 12:08:32,503 loss: 27.905060
2016-07-05 12:08:47,827 epoch 0/20000, step 30/62500
2016-07-05 12:08:51,807 loss: 26.288921
2016-07-05 12:09:06,113 epoch 0/20000, step 31/62500
2016-07-05 12:09:10,092 loss: 27.275520
2016-07-05 12:09:24,501 epoch 0/20000, step 32/62500
2016-07-05 12:09:28,485 loss: 29.022820
2016-07-05 12:09:43,007 epoch 0/20000, step 33/62500
2016-07-05 12:09:46,990 loss: 27.252121
2016-07-05 12:10:01,171 epoch 0/20000, step 34/62500
2016-07-05 12:10:05,147 loss: 26.443619
2016-07-05 12:10:19,505 epoch 0/20000, step 35/62500
2016-07-05 12:10:23,480 loss: 30.079762
2016-07-05 12:10:37,744 epoch 0/20000, step 36/62500
2016-07-05 12:10:41,721 loss: 26.247107
2016-07-05 12:10:56,017 epoch 0/20000, step 37/62500
2016-07-05 12:10:59,992 loss: 27.083065
2016-07-05 12:11:14,331 epoch 0/20000, step 38/62500
2016-07-05 12:11:18,316 loss: 29.711174
2016-07-05 12:11:32,762 epoch 0/20000, step 39/62500
2016-07-05 12:11:36,740 loss: 26.087057
2016-07-05 12:11:51,097 epoch 0/20000, step 40/62500
2016-07-05 12:11:55,079 loss: 27.466608
2016-07-05 12:12:09,406 epoch 0/20000, step 41/62500
2016-07-05 12:12:13,393 loss: 27.825190
2016-07-05 12:12:27,674 epoch 0/20000, step 42/62500
2016-07-05 12:12:31,651 loss: 26.906975
2016-07-05 12:12:45,843 epoch 0/20000, step 43/62500
2016-07-05 12:12:49,815 loss: 28.568817
2016-07-05 12:13:04,184 epoch 0/20000, step 44/62500
2016-07-05 12:13:08,161 loss: 27.141310
2016-07-05 12:13:22,470 epoch 0/20000, step 45/62500
2016-07-05 12:13:26,452 loss: 26.684214
2016-07-05 12:13:41,622 epoch 0/20000, step 46/62500
2016-07-05 12:13:45,598 loss: 26.187344
2016-07-05 12:13:59,892 epoch 0/20000, step 47/62500
2016-07-05 12:14:03,902 loss: 28.795563
2016-07-05 12:14:18,205 epoch 0/20000, step 48/62500
2016-07-05 12:14:22,188 loss: 26.199902
2016-07-05 12:14:36,421 epoch 0/20000, step 49/62500
2016-07-05 12:14:40,402 loss: 26.055723
2016-07-05 12:14:54,724 epoch 0/20000, step 50/62500
2016-07-05 12:14:58,707 loss: 29.603355
2016-07-05 12:15:13,676 epoch 0/20000, step 51/62500
2016-07-05 12:15:17,657 loss: 26.350925
2016-07-05 12:15:31,925 epoch 0/20000, step 52/62500
2016-07-05 12:15:35,899 loss: 26.430077
2016-07-05 12:15:50,309 epoch 0/20000, step 53/62500
2016-07-05 12:15:54,285 loss: 28.304237
2016-07-05 12:16:08,697 epoch 0/20000, step 54/62500
2016-07-05 12:16:12,800 loss: 27.389343
2016-07-05 12:16:27,230 epoch 0/20000, step 55/62500
2016-07-05 12:16:31,211 loss: 25.756805
2016-07-05 12:16:45,645 epoch 0/20000, step 56/62500
2016-07-05 12:16:49,627 loss: 26.703304
2016-07-05 12:17:04,004 epoch 0/20000, step 57/62500
2016-07-05 12:17:07,981 loss: 28.341097
2016-07-05 12:17:24,016 epoch 0/20000, step 58/62500
2016-07-05 12:17:28,346 loss: 26.548876
2016-07-05 12:17:44,003 epoch 0/20000, step 59/62500
2016-07-05 12:17:47,973 loss: 25.779350
2016-07-05 12:18:02,238 epoch 0/20000, step 60/62500
2016-07-05 12:18:06,217 loss: 29.190075
2016-07-05 12:18:20,948 epoch 0/20000, step 61/62500
2016-07-05 12:18:24,923 loss: 25.425623
2016-07-05 12:18:39,161 epoch 0/20000, step 62/62500
2016-07-05 12:18:43,138 loss: 26.262501
2016-07-05 12:18:57,492 epoch 0/20000, step 63/62500
2016-07-05 12:19:01,473 loss: 28.681419
2016-07-05 12:19:15,769 epoch 0/20000, step 64/62500
2016-07-05 12:19:20,201 loss: 25.141087
2016-07-05 12:19:34,592 epoch 0/20000, step 65/62500
2016-07-05 12:19:38,566 loss: 26.425560
2016-07-05 12:19:52,819 epoch 0/20000, step 66/62500
2016-07-05 12:19:56,795 loss: 26.672207
2016-07-05 12:20:11,071 epoch 0/20000, step 67/62500
2016-07-05 12:20:15,047 loss: 25.789696
2016-07-05 12:20:29,244 epoch 0/20000, step 68/62500
2016-07-05 12:20:33,224 loss: 27.234827
2016-07-05 12:20:47,500 epoch 0/20000, step 69/62500
2016-07-05 12:20:51,479 loss: 25.896225
2016-07-05 12:21:05,708 epoch 0/20000, step 70/62500
2016-07-05 12:21:10,393 loss: 25.424686
2016-07-05 12:21:25,037 epoch 0/20000, step 71/62500
2016-07-05 12:21:29,017 loss: 24.874687
2016-07-05 12:21:43,290 epoch 0/20000, step 72/62500
2016-07-05 12:21:47,267 loss: 27.358627
2016-07-05 12:22:01,571 epoch 0/20000, step 73/62500
2016-07-05 12:22:05,553 loss: 24.860886
2016-07-05 12:22:19,805 epoch 0/20000, step 74/62500
2016-07-05 12:22:23,784 loss: 24.712437
2016-07-05 12:22:39,348 epoch 0/20000, step 75/62500
2016-07-05 12:22:43,326 loss: 28.062801
2016-07-05 12:22:57,567 epoch 0/20000, step 76/62500
2016-07-05 12:23:01,552 loss: 24.989025
2016-07-05 12:23:15,857 epoch 0/20000, step 77/62500
2016-07-05 12:23:19,839 loss: 25.019354
2016-07-05 12:23:34,226 epoch 0/20000, step 78/62500
2016-07-05 12:23:38,205 loss: 26.709766
2016-07-05 12:23:52,561 epoch 0/20000, step 79/62500
2016-07-05 12:23:56,541 loss: 25.783665
2016-07-05 12:24:10,774 epoch 0/20000, step 80/62500
2016-07-05 12:24:14,752 loss: 24.274412
2016-07-05 12:24:29,077 epoch 0/20000, step 81/62500
2016-07-05 12:24:33,057 loss: 25.117544
2016-07-05 12:24:47,351 epoch 0/20000, step 82/62500
2016-07-05 12:24:51,323 loss: 26.584438
2016-07-05 12:25:05,573 epoch 0/20000, step 83/62500
2016-07-05 12:25:09,545 loss: 24.903065
2016-07-05 12:25:23,779 epoch 0/20000, step 84/62500
2016-07-05 12:25:27,756 loss: 24.246101
2016-07-05 12:25:42,154 epoch 0/20000, step 85/62500
2016-07-05 12:25:46,133 loss: 27.332836
2016-07-05 12:26:00,442 epoch 0/20000, step 86/62500
2016-07-05 12:26:04,426 loss: 23.826950
2016-07-05 12:26:18,741 epoch 0/20000, step 87/62500
2016-07-05 12:26:22,722 loss: 24.704880
2016-07-05 12:26:36,972 epoch 0/20000, step 88/62500
2016-07-05 12:26:40,961 loss: 26.724352
2016-07-05 12:26:55,363 epoch 0/20000, step 89/62500
2016-07-05 12:26:59,337 loss: 23.538040
2016-07-05 12:27:13,640 epoch 0/20000, step 90/62500
2016-07-05 12:27:17,619 loss: 24.752291
2016-07-05 12:27:31,830 epoch 0/20000, step 91/62500
2016-07-05 12:27:36,758 loss: 24.892693
2016-07-05 12:27:51,031 epoch 0/20000, step 92/62500
2016-07-05 12:27:55,008 loss: 24.176916
2016-07-05 12:28:09,274 epoch 0/20000, step 93/62500
2016-07-05 12:28:13,245 loss: 25.441288
2016-07-05 12:28:27,784 epoch 0/20000, step 94/62500
2016-07-05 12:28:31,791 loss: 24.282429
2016-07-05 12:28:46,354 epoch 0/20000, step 95/62500
2016-07-05 12:28:50,335 loss: 23.839642
2016-07-05 12:29:04,595 epoch 0/20000, step 96/62500
2016-07-05 12:29:08,568 loss: 23.271845
2016-07-05 12:29:22,851 epoch 0/20000, step 97/62500
2016-07-05 12:29:26,829 loss: 25.685987
2016-07-05 12:29:41,530 epoch 0/20000, step 98/62500
2016-07-05 12:29:45,509 loss: 23.305063
2016-07-05 12:29:59,842 epoch 0/20000, step 99/62500
2016-07-05 12:30:03,822 loss: 23.206203
2016-07-05 12:30:18,104 epoch 0/20000, step 100/62500
2016-07-05 12:30:22,080 loss: 26.249142
2016-07-05 12:30:36,686 epoch 0/20000, step 101/62500
2016-07-05 12:30:40,670 loss: 23.465088
2016-07-05 12:30:54,978 epoch 0/20000, step 102/62500
2016-07-05 12:30:58,957 loss: 23.541931
2016-07-05 12:31:13,160 epoch 0/20000, step 103/62500
2016-07-05 12:31:17,142 loss: 25.134327
2016-07-05 12:31:31,682 epoch 0/20000, step 104/62500
2016-07-05 12:31:35,660 loss: 24.259598
2016-07-05 12:31:49,971 epoch 0/20000, step 105/62500
2016-07-05 12:31:53,943 loss: 22.962397
2016-07-05 12:32:09,578 epoch 0/20000, step 106/62500
2016-07-05 12:32:13,557 loss: 23.735750
2016-07-05 12:32:27,837 epoch 0/20000, step 107/62500
2016-07-05 12:32:31,812 loss: 25.120136
2016-07-05 12:32:47,270 epoch 0/20000, step 108/62500
2016-07-05 12:32:51,243 loss: 23.583534
2016-07-05 12:33:05,662 epoch 0/20000, step 109/62500
2016-07-05 12:33:09,644 loss: 23.020584
2016-07-05 12:33:23,977 epoch 0/20000, step 110/62500
2016-07-05 12:33:27,956 loss: 25.801239
2016-07-05 12:33:42,458 epoch 0/20000, step 111/62500
2016-07-05 12:33:46,437 loss: 22.563435
2016-07-05 12:34:00,819 epoch 0/20000, step 112/62500
2016-07-05 12:34:04,800 loss: 23.488602
2016-07-05 12:34:19,097 epoch 0/20000, step 113/62500
2016-07-05 12:34:23,064 loss: 25.312115
2016-07-05 12:34:37,586 epoch 0/20000, step 114/62500
2016-07-05 12:34:41,553 loss: 22.429031
2016-07-05 12:34:55,727 epoch 0/20000, step 115/62500
2016-07-05 12:34:59,696 loss: 23.922884
2016-07-05 12:35:13,966 epoch 0/20000, step 116/62500
2016-07-05 12:35:17,931 loss: 24.276644
2016-07-05 12:35:32,115 epoch 0/20000, step 117/62500
2016-07-05 12:35:36,088 loss: 23.420185
2016-07-05 12:35:50,359 epoch 0/20000, step 118/62500
2016-07-05 12:35:54,328 loss: 24.312559
2016-07-05 12:36:08,687 epoch 0/20000, step 119/62500
2016-07-05 12:36:12,660 loss: 23.217987
2016-07-05 12:36:26,848 epoch 0/20000, step 120/62500
2016-07-05 12:36:30,818 loss: 22.778845
2016-07-05 12:36:45,019 epoch 0/20000, step 121/62500
2016-07-05 12:36:48,983 loss: 22.199625
2016-07-05 12:37:03,490 epoch 0/20000, step 122/62500
2016-07-05 12:37:07,461 loss: 24.546541
2016-07-05 12:37:21,718 epoch 0/20000, step 123/62500
2016-07-05 12:37:25,687 loss: 22.251640
2016-07-05 12:37:39,941 epoch 0/20000, step 124/62500
2016-07-05 12:37:44,822 loss: 22.188677
2016-07-05 12:37:59,796 epoch 0/20000, step 125/62500
2016-07-05 12:38:03,938 loss: 25.042213
2016-07-05 12:38:18,255 epoch 0/20000, step 126/62500
2016-07-05 12:38:22,225 loss: 22.455883
2016-07-05 12:38:36,458 epoch 0/20000, step 127/62500
2016-07-05 12:38:40,428 loss: 22.530849
2016-07-05 12:38:54,567 epoch 0/20000, step 128/62500
2016-07-05 12:38:58,539 loss: 24.023350
2016-07-05 12:39:12,804 epoch 0/20000, step 129/62500
2016-07-05 12:39:16,801 loss: 23.182161
2016-07-05 12:39:31,047 epoch 0/20000, step 130/62500
2016-07-05 12:39:35,017 loss: 21.999027
2016-07-05 12:39:49,477 epoch 0/20000, step 131/62500
2016-07-05 12:39:53,442 loss: 22.726601
2016-07-05 12:40:07,958 epoch 0/20000, step 132/62500
2016-07-05 12:40:11,925 loss: 24.043644
2016-07-05 12:40:26,314 epoch 0/20000, step 133/62500
2016-07-05 12:40:30,282 loss: 22.580856
2016-07-05 12:40:44,560 epoch 0/20000, step 134/62500
2016-07-05 12:40:48,529 loss: 22.101448
2016-07-05 12:41:02,796 epoch 0/20000, step 135/62500
2016-07-05 12:41:06,766 loss: 24.688911
2016-07-05 12:41:20,926 epoch 0/20000, step 136/62500
2016-07-05 12:41:24,900 loss: 21.615982
2016-07-05 12:41:39,282 epoch 0/20000, step 137/62500
2016-07-05 12:41:43,253 loss: 22.579208
2016-07-05 12:41:57,543 epoch 0/20000, step 138/62500
2016-07-05 12:42:01,514 loss: 24.240253
2016-07-05 12:42:15,785 epoch 0/20000, step 139/62500
2016-07-05 12:42:19,757 loss: 21.506573
2016-07-05 12:42:34,143 epoch 0/20000, step 140/62500
2016-07-05 12:42:38,113 loss: 22.634092
2016-07-05 12:42:53,472 epoch 0/20000, step 141/62500
2016-07-05 12:42:57,448 loss: 22.700130
2016-07-05 12:43:11,759 epoch 0/20000, step 142/62500
2016-07-05 12:43:15,728 loss: 22.177397
2016-07-05 12:43:29,966 epoch 0/20000, step 143/62500
2016-07-05 12:43:33,939 loss: 23.164907
2016-07-05 12:43:48,530 epoch 0/20000, step 144/62500
2016-07-05 12:43:52,503 loss: 22.306087
2016-07-05 12:44:06,718 epoch 0/20000, step 145/62500
2016-07-05 12:44:10,691 loss: 21.862713
2016-07-05 12:44:24,976 epoch 0/20000, step 146/62500
2016-07-05 12:44:28,941 loss: 21.281416
2016-07-05 12:44:43,218 epoch 0/20000, step 147/62500
2016-07-05 12:44:47,188 loss: 23.588295
2016-07-05 12:45:01,427 epoch 0/20000, step 148/62500
2016-07-05 12:45:05,397 loss: 21.361639
2016-07-05 12:45:19,552 epoch 0/20000, step 149/62500
2016-07-05 12:45:23,521 loss: 21.319191
2016-07-05 12:45:37,870 epoch 0/20000, step 150/62500
2016-07-05 12:45:41,841 loss: 23.991259
2016-07-05 12:45:56,148 epoch 0/20000, step 151/62500
2016-07-05 12:46:00,114 loss: 21.609852
2016-07-05 12:46:14,459 epoch 0/20000, step 152/62500
2016-07-05 12:46:18,425 loss: 21.652689
2016-07-05 12:46:32,673 epoch 0/20000, step 153/62500
2016-07-05 12:46:36,642 loss: 23.062098
2016-07-05 12:46:50,846 epoch 0/20000, step 154/62500
2016-07-05 12:46:54,819 loss: 22.256966
2016-07-05 12:47:09,111 epoch 0/20000, step 155/62500
2016-07-05 12:47:13,078 loss: 21.157272
2016-07-05 12:47:27,333 epoch 0/20000, step 156/62500
2016-07-05 12:47:31,301 loss: 21.847290
2016-07-05 12:47:45,807 epoch 0/20000, step 157/62500
2016-07-05 12:47:50,580 loss: 23.110481
2016-07-05 12:48:05,156 epoch 0/20000, step 158/62500
2016-07-05 12:48:09,131 loss: 21.689390
2016-07-05 12:48:23,361 epoch 0/20000, step 159/62500
2016-07-05 12:48:27,330 loss: 21.285547
2016-07-05 12:48:41,676 epoch 0/20000, step 160/62500
2016-07-05 12:48:45,645 loss: 23.708141
2016-07-05 12:48:59,860 epoch 0/20000, step 161/62500
2016-07-05 12:49:03,833 loss: 20.764786
2016-07-05 12:49:18,099 epoch 0/20000, step 162/62500
2016-07-05 12:49:22,066 loss: 21.754274
2016-07-05 12:49:36,432 epoch 0/20000, step 163/62500
2016-07-05 12:49:40,403 loss: 23.295580
2016-07-05 12:49:54,681 epoch 0/20000, step 164/62500
2016-07-05 12:49:58,654 loss: 20.677490
2016-07-05 12:50:12,875 epoch 0/20000, step 165/62500
2016-07-05 12:50:16,847 loss: 21.761356
2016-07-05 12:50:31,160 epoch 0/20000, step 166/62500
2016-07-05 12:50:35,128 loss: 21.843266
2016-07-05 12:50:49,672 epoch 0/20000, step 167/62500
2016-07-05 12:50:53,643 loss: 21.359497
2016-07-05 12:51:07,939 epoch 0/20000, step 168/62500
2016-07-05 12:51:11,910 loss: 22.197807
2016-07-05 12:51:26,317 epoch 0/20000, step 169/62500
2016-07-05 12:51:30,282 loss: 21.530499
2016-07-05 12:51:44,579 epoch 0/20000, step 170/62500
2016-07-05 12:51:48,547 loss: 21.045246
2016-07-05 12:52:02,746 epoch 0/20000, step 171/62500
2016-07-05 12:52:06,719 loss: 20.446117
2016-07-05 12:52:20,955 epoch 0/20000, step 172/62500
2016-07-05 12:52:24,930 loss: 22.725487
2016-07-05 12:52:39,236 epoch 0/20000, step 173/62500
2016-07-05 12:52:43,204 loss: 20.558229
2016-07-05 12:52:58,605 epoch 0/20000, step 174/62500
2016-07-05 12:53:02,579 loss: 20.530254
2016-07-05 12:53:16,855 epoch 0/20000, step 175/62500
2016-07-05 12:53:20,820 loss: 23.025993
2016-07-05 12:53:35,126 epoch 0/20000, step 176/62500
2016-07-05 12:53:39,096 loss: 20.856556
2016-07-05 12:53:53,467 epoch 0/20000, step 177/62500
2016-07-05 12:53:57,439 loss: 20.852102
2016-07-05 12:54:11,695 epoch 0/20000, step 178/62500
2016-07-05 12:54:15,666 loss: 22.188705
2016-07-05 12:54:29,936 epoch 0/20000, step 179/62500
2016-07-05 12:54:33,908 loss: 21.421495
2016-07-05 12:54:48,653 epoch 0/20000, step 180/62500
2016-07-05 12:54:52,628 loss: 20.392128
2016-07-05 12:55:06,885 epoch 0/20000, step 181/62500
2016-07-05 12:55:10,856 loss: 21.051643
2016-07-05 12:55:25,087 epoch 0/20000, step 182/62500
2016-07-05 12:55:29,056 loss: 22.269478
2016-07-05 12:55:43,255 epoch 0/20000, step 183/62500
2016-07-05 12:55:47,226 loss: 20.877722
2016-07-05 12:56:01,436 epoch 0/20000, step 184/62500
2016-07-05 12:56:05,424 loss: 20.546101
2016-07-05 12:56:19,694 epoch 0/20000, step 185/62500
2016-07-05 12:56:23,661 loss: 22.822212
2016-07-05 12:56:37,978 epoch 0/20000, step 186/62500
2016-07-05 12:56:41,947 loss: 19.993000
2016-07-05 12:56:56,212 epoch 0/20000, step 187/62500
2016-07-05 12:57:00,180 loss: 21.001736
2016-07-05 12:57:14,561 epoch 0/20000, step 188/62500
2016-07-05 12:57:18,535 loss: 22.538691
2016-07-05 12:57:32,817 epoch 0/20000, step 189/62500
2016-07-05 12:57:36,794 loss: 20.441076
2016-07-05 12:57:51,147 epoch 0/20000, step 190/62500
2016-07-05 12:57:55,963 loss: 21.186001
2016-07-05 12:58:10,362 epoch 0/20000, step 191/62500
2016-07-05 12:58:14,329 loss: 21.351851
2016-07-05 12:58:28,615 epoch 0/20000, step 192/62500
2016-07-05 12:58:32,582 loss: 20.783726
2016-07-05 12:58:46,843 epoch 0/20000, step 193/62500
2016-07-05 12:58:50,814 loss: 21.359257
2016-07-05 12:59:05,241 epoch 0/20000, step 194/62500
2016-07-05 12:59:09,213 loss: 20.868647
2016-07-05 12:59:23,496 epoch 0/20000, step 195/62500
2016-07-05 12:59:27,461 loss: 20.327875
2016-07-05 12:59:41,638 epoch 0/20000, step 196/62500
2016-07-05 12:59:45,607 loss: 19.705135
2016-07-05 12:59:59,894 epoch 0/20000, step 197/62500
2016-07-05 13:00:03,880 loss: 21.971136
2016-07-05 13:00:18,237 epoch 0/20000, step 198/62500
2016-07-05 13:00:22,213 loss: 19.853899
2016-07-05 13:00:36,478 epoch 0/20000, step 199/62500
2016-07-05 13:00:40,452 loss: 19.838627
2016-07-05 13:00:54,719 epoch 0/20000, step 200/62500
2016-07-05 13:00:58,694 loss: 22.172150
2016-07-05 13:01:13,006 epoch 0/20000, step 201/62500
2016-07-05 13:01:16,974 loss: 20.206011
2016-07-05 13:01:31,250 epoch 0/20000, step 202/62500
2016-07-05 13:01:35,224 loss: 20.151791
2016-07-05 13:01:49,492 epoch 0/20000, step 203/62500
2016-07-05 13:01:53,466 loss: 21.425331
2016-07-05 13:02:07,754 epoch 0/20000, step 204/62500
2016-07-05 13:02:11,729 loss: 20.693356
2016-07-05 13:02:26,069 epoch 0/20000, step 205/62500
2016-07-05 13:02:30,041 loss: 19.726744
2016-07-05 13:02:44,323 epoch 0/20000, step 206/62500
2016-07-05 13:02:48,291 loss: 20.362267
2016-07-05 13:03:03,778 epoch 0/20000, step 207/62500
2016-07-05 13:03:07,748 loss: 21.540318
2016-07-05 13:03:22,042 epoch 0/20000, step 208/62500
2016-07-05 13:03:26,015 loss: 20.172831
2016-07-05 13:03:40,310 epoch 0/20000, step 209/62500
2016-07-05 13:03:44,280 loss: 19.908630
2016-07-05 13:03:58,518 epoch 0/20000, step 210/62500
2016-07-05 13:04:02,501 loss: 22.055153
2016-07-05 13:04:16,908 epoch 0/20000, step 211/62500
2016-07-05 13:04:20,881 loss: 19.326891
2016-07-05 13:04:35,170 epoch 0/20000, step 212/62500
2016-07-05 13:04:39,144 loss: 20.362001
2016-07-05 13:04:53,443 epoch 0/20000, step 213/62500
2016-07-05 13:04:57,420 loss: 21.725090
2016-07-05 13:05:11,759 epoch 0/20000, step 214/62500
2016-07-05 13:05:15,733 loss: 19.275784
2016-07-05 13:05:30,123 epoch 0/20000, step 215/62500
2016-07-05 13:05:34,098 loss: 20.311176
2016-07-05 13:05:48,421 epoch 0/20000, step 216/62500
2016-07-05 13:05:52,397 loss: 20.462374
2016-07-05 13:06:06,801 epoch 0/20000, step 217/62500
2016-07-05 13:06:10,777 loss: 20.026970
2016-07-05 13:06:25,053 epoch 0/20000, step 218/62500
2016-07-05 13:06:29,024 loss: 20.581169
2016-07-05 13:06:43,374 epoch 0/20000, step 219/62500
2016-07-05 13:06:47,346 loss: 20.299866
2016-07-05 13:07:01,672 epoch 0/20000, step 220/62500
2016-07-05 13:07:05,646 loss: 19.708061
2016-07-05 13:07:19,875 epoch 0/20000, step 221/62500
2016-07-05 13:07:23,848 loss: 19.063969
2016-07-05 13:07:38,081 epoch 0/20000, step 222/62500
2016-07-05 13:07:42,054 loss: 21.329899
2016-07-05 13:07:56,587 epoch 0/20000, step 223/62500
2016-07-05 13:08:01,276 loss: 19.253717
2016-07-05 13:08:15,562 epoch 0/20000, step 224/62500
2016-07-05 13:08:19,538 loss: 19.250912
2016-07-05 13:08:33,852 epoch 0/20000, step 225/62500
2016-07-05 13:08:37,827 loss: 21.439201
2016-07-05 13:08:52,070 epoch 0/20000, step 226/62500
2016-07-05 13:08:56,042 loss: 19.663746
2016-07-05 13:09:10,217 epoch 0/20000, step 227/62500
2016-07-05 13:09:14,244 loss: 19.560020
2016-07-05 13:09:30,401 epoch 0/20000, step 228/62500
2016-07-05 13:09:34,374 loss: 20.781712
2016-07-05 13:09:48,654 epoch 0/20000, step 229/62500
2016-07-05 13:09:52,624 loss: 20.081562
2016-07-05 13:10:06,966 epoch 0/20000, step 230/62500
2016-07-05 13:10:10,938 loss: 19.170654
2016-07-05 13:10:25,231 epoch 0/20000, step 231/62500
2016-07-05 13:10:29,205 loss: 19.789032
2016-07-05 13:10:43,634 epoch 0/20000, step 232/62500
2016-07-05 13:10:47,605 loss: 20.933746
2016-07-05 13:11:01,906 epoch 0/20000, step 233/62500
2016-07-05 13:11:05,881 loss: 19.585922
2016-07-05 13:11:20,078 epoch 0/20000, step 234/62500
2016-07-05 13:11:24,050 loss: 19.384949
2016-07-05 13:11:38,413 epoch 0/20000, step 235/62500
2016-07-05 13:11:42,388 loss: 21.419046
2016-07-05 13:11:56,614 epoch 0/20000, step 236/62500
2016-07-05 13:12:00,607 loss: 18.777397
2016-07-05 13:12:14,962 epoch 0/20000, step 237/62500
2016-07-05 13:12:18,933 loss: 19.838099
2016-07-05 13:12:33,193 epoch 0/20000, step 238/62500
2016-07-05 13:12:37,167 loss: 21.131802
2016-07-05 13:12:51,587 epoch 0/20000, step 239/62500
2016-07-05 13:12:55,571 loss: 18.745522
2016-07-05 13:13:10,849 epoch 0/20000, step 240/62500
2016-07-05 13:13:14,818 loss: 19.760607
2016-07-05 13:13:29,097 epoch 0/20000, step 241/62500
2016-07-05 13:13:33,070 loss: 19.948246
2016-07-05 13:13:47,337 epoch 0/20000, step 242/62500
2016-07-05 13:13:51,315 loss: 19.534470
2016-07-05 13:14:05,634 epoch 0/20000, step 243/62500
2016-07-05 13:14:09,607 loss: 19.962942
2016-07-05 13:14:23,983 epoch 0/20000, step 244/62500
2016-07-05 13:14:27,952 loss: 19.862375
2016-07-05 13:14:43,505 epoch 0/20000, step 245/62500
2016-07-05 13:14:47,477 loss: 19.230259
2016-07-05 13:15:01,788 epoch 0/20000, step 246/62500
2016-07-05 13:15:05,761 loss: 18.561546
2016-07-05 13:15:20,071 epoch 0/20000, step 247/62500
2016-07-05 13:15:24,809 loss: 20.839230
2016-07-05 13:17:32,450 loading training data
2016-07-05 13:17:32,592 loading test data
2016-07-05 13:17:33,568 epoch 0/20000, step 0/625000
2016-07-05 13:17:39,916 loss: 30.016365
2016-07-05 13:18:03,315 model saved in file: /home/local/ANT/zelunluo/Documents/checkpoint/model.ckpt
2016-07-05 13:18:03,315 epoch 0/20000, step 1/625000
2016-07-05 13:18:09,653 loss: 26.718315
2016-07-05 13:18:32,161 epoch 0/20000, step 2/625000
2016-07-05 13:18:38,501 loss: 26.876842
2016-07-05 13:19:01,130 epoch 0/20000, step 3/625000
2016-07-05 13:19:12,294 loading training data (2000 examples)
2016-07-05 13:19:12,502 loading test data (3000 examples)
2016-07-05 13:19:13,213 epoch 0/20000, step 0/625000
2016-07-05 13:19:19,549 loss: 30.017174
2016-07-05 13:19:42,565 model saved in file: /home/local/ANT/zelunluo/Documents/checkpoint/model.ckpt
2016-07-05 13:19:42,566 epoch 0/20000, step 1/625000
2016-07-05 13:19:48,892 loss: 26.718218
2016-07-05 13:20:11,513 epoch 0/20000, step 2/625000
2016-07-05 13:20:17,847 loss: 26.877605
2016-07-05 13:20:40,636 epoch 0/20000, step 3/625000
2016-07-05 13:20:46,968 loss: 23.637289
2016-07-05 13:21:09,613 epoch 0/20000, step 4/625000
2016-07-05 13:21:41,035 loading training data (2000 examples)
2016-07-05 13:21:41,241 loading test data (3000 examples)
2016-07-05 13:21:41,946 epoch 0/20000, step 0/625000
